{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D2_CognitiveStructures/student/W2D2_Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D2_CognitiveStructures/student/W2D2_Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 3: Generalizing representations\n",
    "\n",
    "**Week 2, Day 2: Cognitive Structures**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Michael Furlong\n",
    "\n",
    "__Content reviewers:__ Hlib Solodzhuk\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 1 hour 20 minutes*\n",
    "\n",
    "In this tutorial, you will observe how the VSAs methods can be applied in structures and environments to allow for efficient generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "from IPython.display import IFrame\n",
    "link_id = \"kj6p3\"\n",
    "\n",
    "print(f\"If you want to download the slides: 'https://osf.io/download/{link_id}'\")\n",
    "\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "# !pip3 install vibecheck datatops --quiet\n",
    "\n",
    "# from vibecheck import DatatopsContentReviewContainer\n",
    "# def content_review(notebook_section: str):\n",
    "#     return DatatopsContentReviewContainer(\n",
    "#         \"\",  # No text prompt - leave this as is\n",
    "#         notebook_section,\n",
    "#         {\n",
    "#             \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "#             \"name\": \"sciencematch_sm\", # change the name of the course : neuromatch_dl, climatematch_ct, etc\n",
    "#             \"user_key\": \"y1x3mpx5\",\n",
    "#         },\n",
    "#     ).render()\n",
    "\n",
    "# feedback_prefix = \"W2D2_T3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "# @markdown\n",
    "\n",
    "# Install sspspace\n",
    "!pip install git+https://github.com/ctn-waterloo/sspspace@neuromatch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "#working with data\n",
    "import numpy as np\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "#interactive display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#modeling\n",
    "import sspspace\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "\n",
    "def plot_vectors(concepts, labels, shape = (32, 32)):\n",
    "    \"\"\"\n",
    "    Plot vector symbols associated with the given concepts.\n",
    "\n",
    "    Inputs:\n",
    "    - concepts (list of sspspace.ssp.SSP): list of concepts which contain associated vectors.\n",
    "    - labels (list of str): list of strings which represent concepts.\n",
    "    - shape (tuple, default = (32, 32)): desired image shape.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        n = len(concepts)\n",
    "        for i in range(len(concepts)):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.imshow(concepts[i].view(dtype=float,type=np.ndarray).reshape(shape), cmap='Greys')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(labels[i])\n",
    "\n",
    "def plot_similarity_matrix(sim_mat, labels, values = False):\n",
    "    \"\"\"\n",
    "    Plot the similarity matrix between vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - labels (list of str): list of strings which represent concepts.\n",
    "    - values (bool): True if we would like to plot values of similarity too.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.imshow(sim_mat, cmap='Greys')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(len(labels)), labels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.yticks(np.arange(len(labels)), labels)\n",
    "        if values:\n",
    "            for x in range(sim_mat.shape[1]):\n",
    "                for y in range(sim_mat.shape[0]):\n",
    "                    plt.text(x, y, f\"{sim_mat[y, x]:.2f}\", fontsize = 8, ha=\"center\", va=\"center\", color=\"green\")\n",
    "        plt.title('Similarity between vector-symbols')\n",
    "        plt.xlabel('Symbols')\n",
    "        plt.ylabel('Symbols')\n",
    "        plt.show()\n",
    "\n",
    "def plot_line_similarity_matrix(sim_mat, xaxis_ticks, multiple_objects = True, labels = None, title = \"Awesome title!\"):\n",
    "    \"\"\"\n",
    "    Plot similarirty matrix (or vector if multiple_objects is False) as lines.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - xaxis_ticks (list): list of ticks to put in x-axis.\n",
    "    - multiple_objects (bool, default = True): True if there are a couple of objects to plot similarity.\n",
    "    - labels (list, default = None): labels to plot.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        if multiple_objects:\n",
    "            for idx, integer_sims in enumerate(sim_mat):\n",
    "                if labels:\n",
    "                    plt.plot(xaxis_ticks, integer_sims.flatten(), label=f'$\\phi$[{idx+1}]', marker='o', ls='--')\n",
    "                else:\n",
    "                    plt.plot(xaxis_ticks, integer_sims.flatten(), marker='o', ls='--')\n",
    "        else:\n",
    "            plt.plot(xaxis_ticks,sim_mat.flatten(), ls='--',marker='o')\n",
    "\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.xlabel('n')\n",
    "    plt.xticks(xaxis_ticks)\n",
    "    if labels:\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_double_line_similarity_matrix(sim_mat, xaxis_ticks, labels, title):\n",
    "    \"\"\"\n",
    "    Plot similarirty matrix (or vector if multiple_objects is False) as lines for two different matrices.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): list of similarity matrix between vectors.\n",
    "    - xaxis_ticks (list): list of ticks to put in x-axis.\n",
    "    - multiple_objects (bool, default = True): True if there are a couple of objects to plot similarity.\n",
    "    - labels (list): labels to plot.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.plot(xaxis_ticks,sim_mat[0].flatten(), ls='--',marker='o', label = labels[0])\n",
    "        plt.plot(xaxis_ticks,sim_mat[1].flatten(), ls='--',marker='o', label = labels[1])\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.xlabel('n')\n",
    "    plt.xticks(xaxis_ticks)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_real_valued_line_similarity(sim_mat, x_range, title):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - x_range (numpy.ndarray): x-axis range.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.plot(x_range, sims)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.title(title)\n",
    "\n",
    "def plot_3d_function(X, Y, zs, titles):\n",
    "    \"\"\"Plot 3D function.\n",
    "\n",
    "    Inputs:\n",
    "    - X (list): list of np.ndarray of x-values.\n",
    "    - Y (list): list of np.ndarray of y-values.\n",
    "    - zs (list): list of np.ndarray of z-values.\n",
    "    - titles (list): list of titles of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        for index, (x, y, z) in enumerate(zip(X, Y, zs)):\n",
    "            fig.add_subplot(1, len(X), index + 1, projection='3d')\n",
    "            plt.gca().plot_surface(x,y,z.reshape(x.shape),cmap='plasma', antialiased=False, linewidth=0)\n",
    "            plt.xlabel(r'$x_{1}$')\n",
    "            plt.ylabel(r'$x_{2}$')\n",
    "            plt.gca().set_zlabel(r'$f(\\mathbf{x})$')\n",
    "            plt.title(titles[index])\n",
    "        plt.show()\n",
    "\n",
    "def plot_performance(bound_performance, bundle_performance, test_sizes, title):\n",
    "    \"\"\"Plot RMSE values for two different representations of the input data.\n",
    "\n",
    "    Inputs:\n",
    "    - bound_performance (list): list of RMSE for bound representation.\n",
    "    - bundle_performance (list): list of RMSE for bundle representation.\n",
    "    - test_sizes (list): x-axis.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.plot(test_sizes, bound_performance, label='Bound Representation')\n",
    "        plt.plot(test_sizes, bundle_performance, label='Bundling Representation', ls='--')\n",
    "        plt.legend()\n",
    "        plt.title(title)\n",
    "        plt.ylabel('RMSE (a.u.)')\n",
    "        plt.xlabel('Test Set Fraction')\n",
    "        plt.show()\n",
    "\n",
    "def plot_2d_similarity(sims, obj_names, size, title_argmax = False):\n",
    "    \"\"\"\n",
    "    Plot 2D similarity between query points (grid) and the ones associated with the objects.\n",
    "\n",
    "    Inputs:\n",
    "    - sims (list): list of similarity values for each of the objects.\n",
    "    - obj_names (list): list of object names.\n",
    "    - size (tuple): to reshape the similarities.\n",
    "    - title_argmax (bool, default = False): looks for the point coordinates as arg max from all similarity value.\n",
    "    \"\"\"\n",
    "    ticks = [0,24,49,74,99]\n",
    "    ticklabels = [-5,-2,0,2,5]\n",
    "    with plt.xkcd():\n",
    "        for obj_idx, obj in enumerate(obj_names):\n",
    "            plt.subplot(1,len(obj_names), 1+obj_idx)\n",
    "            plt.imshow(sims[obj_idx].reshape(size), origin='lower', vmin=-1, vmax=1)\n",
    "            plt.gca().set_xticks(ticks)\n",
    "            plt.gca().set_xticklabels(ticklabels)\n",
    "            if obj_idx == 0:\n",
    "                plt.gca().set_yticks(ticks)\n",
    "                plt.gca().set_yticklabels(ticklabels)\n",
    "            else:\n",
    "                plt.gca().set_yticks([])\n",
    "            if not title_argmax:\n",
    "                plt.title(f'{obj}, {positions[obj_idx]}')\n",
    "            else:\n",
    "                plt.title(f'{obj}, {query_xs[sims[obj_idx].argmax()]}')\n",
    "        plt.show()\n",
    "\n",
    "def plot_unbinding_objects_map(sims, positions, query_xs, size):\n",
    "    \"\"\"\n",
    "    Plot 2D similarity between query points (grid) and the unbinded from the objects map.\n",
    "\n",
    "    Inputs:\n",
    "    - sims (np.ndarray): similarity values for each of the query points with the map.\n",
    "    - positions (np.ndarray): positions of the objects.\n",
    "    - query_xs (np.ndarray): grid points.\n",
    "    - size (tuple): to reshape the similarities.\n",
    "\n",
    "    \"\"\"\n",
    "    ticks = [0,24,49,74,99]\n",
    "    ticklabels = [-5,-2,0,2,5]\n",
    "    with plt.xkcd():\n",
    "        plt.imshow(sims.reshape(size), origin='lower')\n",
    "\n",
    "        for idx, marker in enumerate(['o','s','^']):\n",
    "            plt.scatter(*get_coordinate(positions[idx,:], query_xs, size), marker=marker,s=100)\n",
    "\n",
    "        plt.gca().set_xticks(ticks)\n",
    "        plt.gca().set_xticklabels(ticklabels)\n",
    "        plt.gca().set_yticks(ticks)\n",
    "        plt.gca().set_yticklabels(ticklabels)\n",
    "        plt.title(f'All Object Locations')\n",
    "        plt.show()\n",
    "\n",
    "def plot_unbinding_positions_map(sims, positions, obj_names):\n",
    "    \"\"\"\n",
    "    Plot 2D similarity between query points (grid) and the unbinded from the positions map.\n",
    "\n",
    "    Inputs:\n",
    "    - sims (np.ndarray): similarity values for each of the query points with the map.\n",
    "    - positions (np.ndarray): test positions to query.\n",
    "    - obj_names (list): names of the objects for labels.\n",
    "    - size (tuple): to reshape the similarities.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.figure(figsize=(25,5))\n",
    "        for pos_idx, pos in enumerate(positions):\n",
    "            plt.subplot(1,len(test_positions), 1+pos_idx)\n",
    "            plt.bar([1,2,3], sims[pos_idx])\n",
    "            plt.ylim([-0.3,1.05])\n",
    "            plt.gca().set_xticks([1,2,3])\n",
    "            plt.gca().set_xticklabels(obj_names, rotation=90)\n",
    "            if pos_idx != 0:\n",
    "                plt.gca().set_yticks([])\n",
    "            plt.title(f'Symbols at {pos}')\n",
    "        plt.show()\n",
    "\n",
    "def plot_training_and_choice(losses, sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot loss progression over training as well as predicted similarities for given rules / correct solutions.\n",
    "\n",
    "    Inputs:\n",
    "    - losses (list): list of loss values.\n",
    "    - sims (list): list of similartiy matrices.\n",
    "    - ant_names (list): list of antecedance names.\n",
    "    - cons_names (list): list of consequent names.\n",
    "    - action_names (list): full list of concepts.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.subplot(1, len(ant_names) + 1, 1)\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Training number')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Error')\n",
    "        index = 1\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')\n",
    "\n",
    "def plot_choice(sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot predicted similarities for given rules / correct solutions.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        index = 0\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.ylabel(\"Similarity\")\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "def get_model(xs, ys, test_size):\n",
    "    \"\"\"Fit linear regression to the given data.\n",
    "\n",
    "    Inputs:\n",
    "    - xs (np.ndarray): input data.\n",
    "    - ys (np.ndarray): outpu data.\n",
    "    - test_size (float): fraction of data to use for test.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xs, ys, random_state=1, test_size=test_size)\n",
    "    return LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "def get_coordinate(x, positions, target_shape):\n",
    "    \"\"\"Return the closest column and row coordinates for the given position.\n",
    "\n",
    "    Inputs:\n",
    "    - x (np.ndarray): query position.\n",
    "    - positions (np.ndarray): all positions.\n",
    "    - target_shape (tuple): shape of the grid.\n",
    "\n",
    "    Outputs:\n",
    "    - coordinates (tuple): column and row positions.\n",
    "    \"\"\"\n",
    "    idx = np.argmin(np.linalg.norm(x - positions, axis=1))\n",
    "    c = idx % target_shape[1]\n",
    "    r = idx // target_shape[1]\n",
    "    return (c,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "set_seed(seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 1: Generalization - Wason Card Task\n",
    "\n",
    "One of the powerful benefits of using these structured representations is being able to generalize to other circumstances.  To demonstrate this, we are going to show how we can use a simple learning rule to learn to extract a generalized rule to different circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Wason Card Task Intro\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'KqMMEDjhbKI')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_wason_card_task_intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 1: Wason Card Task\n",
    "\n",
    "We are going to test the generalization property on the Wason Card Task, where a person is told a rule of the form \"if the card is even, then the back is blue\", they are then presented with a number of cards with either an odd number, an even number, a red back, or a blue back.  The participant is asked which cards they have to flip to determine that the rule is true.\n",
    "\n",
    "In this case, the participant needs to flip only the even card(s), as the rule does not state whether or not odd numbers can have blue backs. \n",
    "\n",
    "At first, we will define all needed concepts. For all noun concepts we would also like to have `not concept` presented in the space, please complete missing code parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "card_states = ['red','blue','odd','even','not','green','prime','implies','ant','relation','cons']\n",
    "encoder = sspspace.DiscreteSPSpace(card_states, ssp_dim=1024, optimize=False)\n",
    "vocab = {c:encoder.encode(c) for c in card_states}\n",
    "\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete creating `not x` concepts.\")\n",
    "###################################################################\n",
    "\n",
    "for a in ['red','blue','odd','even','green','prime']:\n",
    "    vocab[f'not*{a}'] = vocab[...] * vocab[a]\n",
    "\n",
    "action_names = ['red','blue','odd','even','green','prime','not*red','not*blue','not*odd','not*even','not*green','not*prime']\n",
    "action_space = np.array([vocab[x] for x in action_names]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "card_states = ['red','blue','odd','even','not','green','prime','implies','ant','relation','cons']\n",
    "encoder = sspspace.DiscreteSPSpace(card_states, ssp_dim=1024, optimize=False)\n",
    "vocab = {c:encoder.encode(c) for c in card_states}\n",
    "\n",
    "for a in ['red','blue','odd','even','green','prime']:\n",
    "    vocab[f'not*{a}'] = vocab['not'] * vocab[a]\n",
    "\n",
    "action_names = ['red','blue','odd','even','green','prime','not*red','not*blue','not*odd','not*even','not*green','not*prime']\n",
    "action_space = np.array([vocab[x] for x in action_names]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are going to set up a simple perceptron-style learning rule, using the HRR (Holographic Reduced Representations) algebra.  We are going to learn a target transformation, $T$, such that given a learning rule, $A^{*} = T\\circledast R$, where $A^{*}$ is the antecedance value bundled with $\\texttt{not}$ bound with the consequent value and $R$ is the learning rule.\n",
    "\n",
    "Rules themselves are going to be composed as country data structures from the previous section. `ant`, `relation` and `cons` are extra concepts which define the structure and which will bind to the specific instances. In the cell below, let us define two rules:\n",
    "\n",
    "$$\\text{blue} \\implies \\text{even}$$\n",
    "$$\\text{odd} \\implies \\text{green}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete creating rules as defined above.\")\n",
    "###################################################################\n",
    "\n",
    "rules = [\n",
    "    (vocab['ant'] * vocab['blue'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab[...]).normalize(),\n",
    "    (vocab[...] * vocab[...] + vocab[...] * vocab[...] + vocab[...] * vocab[...]).normalize(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "rules = [\n",
    "    (vocab['ant'] * vocab['blue'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['even']).normalize(),\n",
    "    (vocab['ant'] * vocab['odd'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['green']).normalize(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are ready to derive the transformation! For that, we will iterate through the rules and solutions for specified number of iterations and update it as the following:\n",
    "\n",
    "$$T \\leftarrow T - \\text{lr}*(A^{*} * \\sim R)$$\n",
    "\n",
    "where $\\text{lr}$ is learning rate constant value. Indeed, as $A^{*} = T\\circledast R$, it makes sense to unbind learning rule to get the current transformation prediction.\n",
    "\n",
    "We will also compute loss progression over the time and log loss function between perfect similarity (ones only for antecedance value and not consequent one) and the one we obtain between prediciton for current transformation and full action space. Complete missing parts of the code in the next cell to complete training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete training loop.\")\n",
    "###################################################################\n",
    "\n",
    "num_iters = 500\n",
    "losses = []\n",
    "sims = []\n",
    "lr = 1e-1\n",
    "ant_names = [\"blue\", \"odd\"]\n",
    "cons_names = [\"even\", \"green\"]\n",
    "\n",
    "transform = np.zeros((1,encoder.ssp_dim))\n",
    "for i in range(num_iters):\n",
    "    loss = 0\n",
    "    for rule, ant_name, cons_name in zip(rules, ant_names, cons_names):\n",
    "        \n",
    "        #perfect similarity\n",
    "        y_true = np.eye(len(action_names))[action_names.index(ant_name),:] + np.eye(len(action_names))[4+action_names.index(cons_name),:]\n",
    "\n",
    "        #prediction with current transform (a_hat = transform * rule)\n",
    "        a_hat = sspspace.SSP(transform) * ...\n",
    "\n",
    "        #similarity with current transform\n",
    "        sim_mat = np.einsum('nd,md->nm', action_space, a_hat)\n",
    "\n",
    "        #cleanup\n",
    "        y_hat = softmax(sim_mat)\n",
    "\n",
    "        #true solution (a* = ant_name + not * cons_name)\n",
    "        a_true = (vocab[ant_name] + vocab['not']*vocab[...]).normalize()\n",
    "\n",
    "        #calculate loss\n",
    "        loss += log_loss(y_true, y_hat)\n",
    "\n",
    "        #update transform (T <- T - lr * (A* * (~rule)))\n",
    "        transform -= (lr) * (... - np.array(... * ~...))\n",
    "        transform = transform / np.linalg.norm(transform)\n",
    "\n",
    "        #save predicted similarities if it is last iteration\n",
    "        if i == num_iters - 1:\n",
    "            sims.append(sim_mat)\n",
    "\n",
    "    #save loss\n",
    "    losses.append(np.copy(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "num_iters = 500\n",
    "losses = []\n",
    "sims = []\n",
    "lr = 1e-1\n",
    "ant_names = [\"blue\", \"odd\"]\n",
    "cons_names = [\"even\", \"green\"]\n",
    "\n",
    "transform = np.zeros((1,encoder.ssp_dim))\n",
    "for i in range(num_iters):\n",
    "    loss = 0\n",
    "    for rule, ant_name, cons_name in zip(rules, ant_names, cons_names):\n",
    "        \n",
    "        #perfect similarity\n",
    "        y_true = np.eye(len(action_names))[action_names.index(ant_name),:] + np.eye(len(action_names))[4+action_names.index(cons_name),:]\n",
    "\n",
    "        #prediction with current transform (a_hat = transform * rule)\n",
    "        a_hat = sspspace.SSP(transform) * rule\n",
    "\n",
    "        #similarity with current transform\n",
    "        sim_mat = np.einsum('nd,md->nm', action_space, a_hat)\n",
    "\n",
    "        #cleanup\n",
    "        y_hat = softmax(sim_mat)\n",
    "\n",
    "        #true solution (a* = ant_name + not * cons_name)\n",
    "        a_true = (vocab[ant_name] + vocab['not']*vocab[cons_name]).normalize()\n",
    "\n",
    "        #calculate loss\n",
    "        loss += log_loss(y_true, y_hat)\n",
    "\n",
    "        #update transform (T <- T - lr * (A* * (~rule)))\n",
    "        transform -= (lr) * (transform - np.array(a_true * ~rule))\n",
    "        transform = transform / np.linalg.norm(transform)\n",
    "\n",
    "        #save predicted similarities if it is last iteration\n",
    "        if i == num_iters - 1:\n",
    "            sims.append(sim_mat)\n",
    "\n",
    "    #save loss\n",
    "    losses.append(np.copy(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_and_choice(losses, sims, ant_names, cons_names, action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's see what happens when we test it on a new rule it hasn't seen before. This time we will use the rule that $\\text{red} \\implies \\text{prime}$. Your task is to complete new rule in the cell below and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete new rule and predict for it.\")\n",
    "###################################################################\n",
    "\n",
    "new_rule = (vocab['ant'] * vocab[...] + vocab['relation'] * ... + vocab['cons'] * vocab[...]).normalize()\n",
    "\n",
    "#apply transform on new rule to test the generalization of the transform\n",
    "a_hat = sspspace.SSP(transform) * ...\n",
    "\n",
    "new_sims = np.einsum('nd,md->nm', action_space, a_hat)\n",
    "y_hat = softmax(new_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "new_rule = (vocab['ant'] * vocab['red'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['prime']).normalize()\n",
    "\n",
    "#apply transform on new rule to test the generalization of the transform\n",
    "a_hat = sspspace.SSP(transform) * new_rule\n",
    "\n",
    "new_sims = np.einsum('nd,md->nm', action_space, a_hat)\n",
    "y_hat = softmax(new_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_choice([new_sims], [\"red\"], [\"prime\"], action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's compare how a standard MLP that isn't aware of the structure in the representation performs. Here, features are going to be the rules and output - solutions. Complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete MLP training.\")\n",
    "###################################################################\n",
    "\n",
    "#features - rules\n",
    "X_train = np.array(...).squeeze()\n",
    "\n",
    "#output - a* for each rule\n",
    "y_train = np.array([\n",
    "    (vocab[ant_names[0]] + vocab['not']*vocab[cons_names[0]]).normalize(),\n",
    "    (vocab[ant_names[1]] + vocab['not']*vocab[cons_names[1]]).normalize(),\n",
    "]).squeeze()\n",
    "\n",
    "regr = MLPRegressor(random_state=1, hidden_layer_sizes=(1024,1024), max_iter=1000).fit(..., ...)\n",
    "\n",
    "a_mlp = regr.predict(new_rule)\n",
    "\n",
    "mlp_sims = np.einsum('nd,md->nm', action_space, a_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "#features - rules\n",
    "X_train = np.array(rules).squeeze()\n",
    "\n",
    "#output - a* for each rule\n",
    "y_train = np.array([\n",
    "    (vocab[ant_names[0]] + vocab['not']*vocab[cons_names[0]]).normalize(),\n",
    "    (vocab[ant_names[1]] + vocab['not']*vocab[cons_names[1]]).normalize(),\n",
    "]).squeeze()\n",
    "\n",
    "regr = MLPRegressor(random_state=1, hidden_layer_sizes=(1024,1024), max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "a_mlp = regr.predict(new_rule)\n",
    "\n",
    "mlp_sims = np.einsum('nd,md->nm', action_space, a_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_choice([mlp_sims], [\"red\"], [\"prime\"], action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see, this model, even though it is a more expressive neural network, simply learns to predict the values it had seen before, when presented with a novel stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Wason Card Task Outro\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'rV3oZXLFrb4')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_wason_card_task_outro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 2: Sample Efficient Learning\n",
    "\n",
    "Estimated timing to here from start of tutorial: 30 minutes\n",
    "\n",
    "In this section we will take a look at how imposing an inductive bias on our feature space can result in more sample-efficient learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Video 3: Function Learning and Inductive Bias\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'NgwMVgaTIbY')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_function_learning_and_inductive_bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 2: Additive Function\n",
    "\n",
    "\n",
    "We will start with an additive function, the Rastrigin function, defined \n",
    "$$\n",
    "f(\\mathbf{x}) = 10*d + \\sum_{i=1}^{d} (x_{i}^{2} - 10 \\cos(2 \\pi x_{i}))\n",
    "$$\n",
    "\n",
    "where $d$ is the dimensionality of the input vector. In the cell below complete missing parts of the function which computes values of the Rastrigin function given the input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the Rastrigin function.\")\n",
    "###################################################################\n",
    "\n",
    "def rastrigin(x):\n",
    "    \"\"\"Compute Rastrigin function for given array of d-dimenstional vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - x (np.ndarray of shape (n, d)): n d-dimensional vectors.\n",
    "\n",
    "    Outputs:\n",
    "    - y (np.ndarray of shape (n, 1)): Rastrigin function value for each of the vectors.\n",
    "    \"\"\"\n",
    "    return 10 * x.shape[1] + np.sum(... - 10 * np.cos(2*np.pi*...), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "def rastrigin(x):\n",
    "    \"\"\"Compute Rastrigin function for given array of d-dimenstional vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - x (np.ndarray of shape (n, d)): n d-dimensional vectors.\n",
    "\n",
    "    Outputs:\n",
    "    - y (np.ndarray of shape (n, 1)): Rastrigin function value for each of the vectors.\n",
    "    \"\"\"\n",
    "    return 10 * x.shape[1] + np.sum(x**2 - 10 * np.cos(2*np.pi*x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code creates 10000 2-dimensional vectors which are going to be served as input to the function (thus, output is of shape (10000, 1))\n",
    "x0 = np.linspace(-5.12, 5.12, 100)\n",
    "X, Y = np.meshgrid(x0,x0)\n",
    "xs = np.vstack((X.flatten(), Y.flatten())).T\n",
    "\n",
    "ys_rastrigin = rastrigin(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_function([X],[Y], [ys_rastrigin.reshape(X.shape)], ['Rastrigin Function'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are going to see which of the inductive biases (suggested mechanism underlying input data) will be more efficient in training the linear regression to get values of the Rastrigin function. For that, we will simply encode 2D input vectors `xs` (we call it 'bound') and with using bundling (encode each of the dimensions separately and then bundle them together). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "ssp_space = sspspace.RandomSSPSpace(domain_dim=2, ssp_dim=1024)\n",
    "bound_phis = ssp_space.encode(xs)\n",
    "\n",
    "ssp_space0 = sspspace.RandomSSPSpace(domain_dim=1, ssp_dim=1024)\n",
    "ssp_space1 = sspspace.RandomSSPSpace(domain_dim=1, ssp_dim=1024)\n",
    "\n",
    "#remember that input to `encode` should be 2-dimensional, thus we need to create extra dimension by applying [:,None]\n",
    "bundle_phis = ssp_space0.encode(xs[:,0][:,None]) + ssp_space1.encode(xs[:,1][:,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, let us define modeling attributes: we will have a couple of different `test_sizes` and we will fit linear regression for each of them right in the loop; then, for each of the models we will evaluate its fit based on RMSE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE loss between true and predicted values (note, that loss is not normalized by the shape).\n",
    "\n",
    "    Inputs:\n",
    "    - y_true (np.ndarray): true values.\n",
    "    - y_pred (np.ndarray): predicted values.\n",
    "\n",
    "    Outputs:\n",
    "    - loss (float): loss value.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "def test_performance(xs, ys, test_sizes):\n",
    "    \"\"\"Fit linear regression to the provided data and evaluate the performance with RMSE loss for different test sizes.\n",
    "\n",
    "    Inputs:\n",
    "    - xs (np.ndarray): input data.\n",
    "    - ys (np.ndarray): output data.\n",
    "    - test_size (list): list of the test sizes.\n",
    "    \"\"\"\n",
    "    performance = []\n",
    "\n",
    "    for test_size in test_sizes:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(xs, ys, random_state=1, test_size=test_size)\n",
    "        regr = LinearRegression().fit(X_train, y_train)\n",
    "        performance.append(np.copy(loss(y_test, regr.predict(X_test))))\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we are ready to traing the models on two different inductive biases of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sizes = np.linspace(0.1,0.75,10)\n",
    "bound_performance = test_performance(bound_phis, ys_rastrigin, test_sizes)\n",
    "bundle_performance = test_performance(bundle_phis, ys_rastrigin, test_sizes)\n",
    "plot_performance(bound_performance, bundle_performance, test_sizes, \"Rastrigin function - RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "What a drastic difference! Let us evaluate visually the performance with `test_size = 0.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_model = get_model(bound_phis, ys_rastrigin, test_size=0.7)\n",
    "bundled_model = get_model(bundle_phis, ys_rastrigin, test_size=0.7)\n",
    "\n",
    "ys_hat_rastrigin_bound = bound_model.predict(bound_phis)\n",
    "ys_hat_rastrigin_bundled = bundled_model.predict(bundle_phis)\n",
    "\n",
    "plot_3d_function([X, X, X], [Y, Y, Y], [ys_rastrigin.reshape(X.shape), ys_hat_rastrigin_bound.reshape(X.shape), ys_hat_rastrigin_bundled.reshape(X.shape)], ['Rastrigin Function - True', 'Bound', 'Bundled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 2 Discussion\n",
    "\n",
    "1. Why do we think bundled representation is superior for Rastrigin function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove explanation\n",
    "\n",
    "\"\"\"\n",
    "Discussion: Why do we think bundled representation is superior for Rastrigin function?\n",
    "\n",
    "As the name of the coding exercise suggests, we have additive function and, thus, bundling being additive operation is superior to simple bound.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_additive_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 3: Non-separable Function\n",
    "\n",
    "Now let's consider a non-separable function.  We will examine the function $f(\\mathbf{x}) = \\sin(x_{1}x_{2})$ over the domain $[-4,4]^{2}$.\n",
    "\n",
    "The same exercise goes here - continue missing parts of the code to get the correct calculation of the defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the non-separable function.\")\n",
    "###################################################################\n",
    "\n",
    "def non_separable(x):\n",
    "    \"\"\"Compute non-separable function for given array of 2-dimenstional vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - x (np.ndarray of shape (n, 2)): n 2-dimensional vectors.\n",
    "\n",
    "    Outputs:\n",
    "    - y (np.ndarray of shape (n, 1)): non-separable function value for each of the vectors.\n",
    "    \"\"\"\n",
    "    return np.sin(np.multiply(x[:,...],x[:,...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "def non_separable(x):\n",
    "    \"\"\"Compute non-separable function for given array of 2-dimenstional vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - x (np.ndarray of shape (n, 2)): n 2-dimensional vectors.\n",
    "\n",
    "    Outputs:\n",
    "    - y (np.ndarray of shape (n, 1)): non-separable function value for each of the vectors.\n",
    "    \"\"\"\n",
    "    return np.sin(np.multiply(x[:,0],x[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.linspace(-4, 4, 100)\n",
    "X, Y = np.meshgrid(x0,x0)\n",
    "xs = np.vstack((X.flatten(), Y.flatten())).T\n",
    "\n",
    "ys_non_separable = non_separable(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_function([X],[Y], [ys_non_separable.reshape(X.shape)], ['Nonseparable Function, $f(\\mathbf{x}) = \\sin(x_{1}x_{2})$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 3 Discussion\n",
    "\n",
    "1. Can you guess by the nature of the function which of the representations will be more efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove explanation\n",
    "\n",
    "\"\"\"\n",
    "Discussion: Can you guess by the nature of the function which of the representations will be more efficient?\n",
    "\n",
    "As here function doesn't have distinct additive parts, we expect bound representation to be better.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We will reuse previously defined spaces for encoding bounded and bundling representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_phis = ssp_space.encode(xs)\n",
    "bundle_phis = ssp_space0.encode(xs[:,0][:,None]) + ssp_space1.encode(xs[:,1][:,None])\n",
    "\n",
    "test_sizes = np.linspace(0.1,0.75,10)\n",
    "bound_performance = test_performance(bound_phis, ys_non_separable, test_sizes)\n",
    "bundle_performance = test_performance(bundle_phis, ys_non_separable, test_sizes)\n",
    "plot_performance(bound_performance, bundle_performance, test_sizes, title = \"Non-separable function - RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Bundling representation can't achieve the same quality even with the small fraction of test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_model = get_model(bound_phis, ys_non_separable, 0.75)\n",
    "bundle_model = get_model(bundle_phis, ys_non_separable, 0.1)\n",
    "\n",
    "ys_hat_bound = bound_model.predict(bound_phis)\n",
    "ys_hat_bundle = bundle_model.predict(bundle_phis)\n",
    "\n",
    "plot_3d_function([X, X, X], [Y, Y, Y], [ys_non_separable.reshape(X.shape), ys_hat_bound.reshape(X.shape), ys_hat_bundle.reshape(X.shape)], ['Non-separable Function - True', 'Bound', 'Bundled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So as we can see, when we pick the right inductive bias, we can do a better job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_non_separable_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 3: Representing Continuous Values\n",
    "\n",
    "Estimated timing to here from start of tutorial: 45 minutes\n",
    "\n",
    "In this section we will use a technique called Fractional Binding to represent continuous values to construct a map of objects distributed over a 2D space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Video 4: Mapping Intro\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'eyjaQq8y_Ag')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_mapping_intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 4: Mixing Discrete Objects With Continuous Space\n",
    "\n",
    "We are going to store three objects in a vector that represents a map. First we are going to create 3 objects (a circle, square, and triangle) like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "obj_names = ['circle','square','triangle']\n",
    "discrete_space = sspspace.DiscreteSPSpace(obj_names, ssp_dim=1024)\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in obj_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Next we are going to create three locations for the objects to reside at and an encoder to transform those coordinates into an SSP representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "ssp_space = sspspace.RandomSSPSpace(domain_dim=2, ssp_dim=1024)\n",
    "positions = np.array([[0,-2],\n",
    "                      [-2,3],\n",
    "                      [3,2]\n",
    "                     ])\n",
    "ssps = {n:ssp_space.encode(x) for n, x in zip(obj_names, positions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Next, in order to see where things are on the map we are going to compute the similarity between encoded places and points in the space. Your task is to complete calculation of similarity values by proposing correct notation for `np.einsum()` function (remember: we would like to calculate similarity between all grid points with the given one associated with the object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim0 = np.linspace(-5,5,101)\n",
    "dim1 = np.linspace(-5,5,101)\n",
    "X,Y = np.meshgrid(dim0,dim1)\n",
    "\n",
    "query_xs = np.vstack((X.flatten(),Y.flatten())).T\n",
    "query_ssps = ssp_space.encode(query_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `np.einsum()` function.\")\n",
    "###################################################################\n",
    "\n",
    "sims = []\n",
    "\n",
    "for obj_idx, obj in enumerate(obj_names):\n",
    "    sims.append(np.einsum(..., ..., ssps[obj].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "sims = []\n",
    "\n",
    "for obj_idx, obj in enumerate(obj_names):\n",
    "    sims.append(np.einsum('nd,d->n', query_ssps, ssps[obj].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_similarity(sims, obj_names, (dim0.size,dim1.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, let's bind these positions with the objects and see how that changes similarity with the map positions. Complete binding operation in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete binding operation for objects and corresponding positions.\")\n",
    "###################################################################\n",
    "\n",
    "#objects are located in `objs` and positions in `ssps`\n",
    "bound_objects = [... * ... for n in obj_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "#objects are located in `objs` and positions in `ssps`\n",
    "bound_objects = [objs[n] * ssps[n] for n in obj_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we will calculate the similarity in the same way we did it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "\n",
    "for obj_idx, obj in enumerate(obj_names):\n",
    "    sims.append(np.einsum('nd,d->n', query_ssps, bound_objects[obj_idx].flatten()))\n",
    "plot_2d_similarity(sims, obj_names, (dim0.size, dim1.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can seem, the similarity is destroyed, which is what we should expect.\n",
    "\n",
    "Next, we are going to create a map out of our bound objects:\n",
    "\n",
    "$$\n",
    "\\mathrm{map} = \\sum_{i=1}^{n} \\phi(x_{i})\\circledast obj_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "ssp_map = sspspace.SSP(np.sum(bound_objects, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can query the map by unbinding the objects we care about. Your task is to complete the unbinding operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the unbinding operation.\")\n",
    "###################################################################\n",
    "\n",
    "sims = []\n",
    "\n",
    "for obj_idx, obj_name in enumerate(obj_names):\n",
    "    #query the object name by unbinding it from the map\n",
    "    query_map = ssp_map * ~objs[...]\n",
    "    sims.append(np.einsum('nd,d->n', query_ssps,query_map.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "sims = []\n",
    "\n",
    "for obj_idx, obj_name in enumerate(obj_names):\n",
    "    #query the object name by unbinding it from the map\n",
    "    query_map = ssp_map * ~objs[obj_name]\n",
    "    sims.append(np.einsum('nd,d->n', query_ssps,query_map.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's observed the resulting similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_similarity(sims, obj_names, (dim0.size, dim1.size), title_argmax = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's look at what happens when we unbind all the symbols at once from the map. Complete bundling and unbinding operations in the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the bundling and unbinding operations.\")\n",
    "###################################################################\n",
    "\n",
    "#unifying bundled representation of all objects\n",
    "all_objs = (objs['circle'] + objs[...] + objs[...]).normalize()\n",
    "\n",
    "#unbind this unifying representation from the map\n",
    "query_map = ... * ~..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "#unifying bundled representation of all objects\n",
    "all_objs = (objs['circle'] + objs['square'] + objs['triangle']).normalize()\n",
    "\n",
    "#unbind this unifying representation from the map\n",
    "query_map = ssp_map * ~all_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = np.einsum('nd,d->n', query_ssps, query_map.flatten())\n",
    "size = (dim0.size,dim1.size)\n",
    "\n",
    "plot_unbinding_objects_map(sims, positions, query_xs, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "But also, we can unbind positions and see what objects exist there. We will use test positions as the ones where objects are located but also two distinct ones to see what will be the result there. In the final exercise you should complete the unbinding of the position operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the unbinding operations.\")\n",
    "###################################################################\n",
    "\n",
    "query_objs = np.vstack([objs[n] for n in obj_names])\n",
    "test_positions = np.vstack((positions, [0,0], [0,-1.5]))\n",
    "\n",
    "sims = []\n",
    "\n",
    "for pos_idx, pos in enumerate(test_positions):\n",
    "    position_ssp = ssp_space.encode(pos[None,:]) #remember we need to have 2-dimensional vectors for `encode()` function\n",
    "    #unbind positions from the map\n",
    "    query_map = ... * ~...\n",
    "    sims.append(np.einsum('nd,d->n', query_objs,query_map.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "query_objs = np.vstack([objs[n] for n in obj_names])\n",
    "test_positions = np.vstack((positions, [0,0], [0,-1.5]))\n",
    "\n",
    "sims = []\n",
    "\n",
    "for pos_idx, pos in enumerate(test_positions):\n",
    "    position_ssp = ssp_space.encode(pos[None,:]) #remember we need to have 2-dimensional vectors for `encode()` function\n",
    "    #unbind positions from the map\n",
    "    query_map = ssp_map * ~position_ssp\n",
    "    sims.append(np.einsum('nd,d->n', query_objs,query_map.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unbinding_positions_map(sims, test_positions, obj_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see from the above plots, when you query what is at the locations of the particular location, we can clearly identify which object is stored at which location.  \n",
    "\n",
    "When we query at the origin (where no object is present) we see that there is no strong candidate element.  But as we move closer to one of the objects (rightmost plot) the similarity starts to increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_mixing_discrete_objects_with_continuous_space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Video 13: Mapping Outro\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'xeFzv1sMdZY')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_mapping_outro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "*Estimated timing of tutorial: 1 hour 20 minutes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Video 14: Conclusions\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', '68JKXf37-YM')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Conclusion slides\n",
    "\n",
    "from IPython.display import IFrame\n",
    "link_id = \"y3zua\"\n",
    "\n",
    "print(f\"If you want to download the slides: 'https://osf.io/download/{link_id}'\")\n",
    "\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_conclusions\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D2_Tutorial1",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "NeuroAI",
   "language": "python",
   "name": "neuroai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
