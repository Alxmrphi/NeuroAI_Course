{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1764495c-fa85-46f1-a72b-1ba805d48e8a",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "source": [
    "# W1D1 Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e229713-7d0c-4ac9-afd1-b935808fec00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835db789-8d58-4cff-b212-4c26726380c5",
   "metadata": {},
   "source": [
    "## Prerequisite knowledge\n",
    "\n",
    "This is the first day, so we assume you have prerequisites equivalent to having taken the CN and DL classes. This dayâ€™s tutorials delve into next-token prediction of a neural network with transformers in PyTorch. We will also talk about attention in this context. You should be familiar from DL W2D5, W3D1. You will work with neural data (actually EMG) in the second tutorial. You should be broadly familiar from the CN class. Please review these precourse materials if necessary!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef995ca-7561-4221-8c56-b1ea07bd288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "!pip3 install vibecheck datatops --quiet\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"neuromatch_cn\",\n",
    "            \"user_key\": \"y1x3mpx5\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W1D1_Intro\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab3846-0223-4914-af4a-f347920ee4c6",
   "metadata": {},
   "source": [
    "## Video\n",
    "\n",
    "Hi everyone, and welcome to the opening session of our tutorial series at the Neuromatch Academy. My name is Samuele Bolotta, I am from Italy and I am the curriculum specialist in the NeuroAI Course. I have a master's in neuroscience and a master's in artificial intelligence and I am excited to be one of the educators guiding you through an exploration of NeuroAI. Our team of content creators, reviewers, production editors, and collaborators has worked hard to put together the educational content we'll be covering.\n",
    "\n",
    "In today's session, we'll be focusing on the concept of Generalization in AI, which is important for developing AI systems that can perform well on unseen data and in various real-world scenarios. This concept is also relevant to understanding cognitive processes and neural mechanisms in neuroscience.\n",
    "\n",
    "Our main goals for today are:\n",
    "\n",
    "1. To discuss the common objectives developers have when deploying AI systems, including performance, latency, SWaP-C (Size, Weight, Power, and Cost), and explainability.\n",
    "\n",
    "2. To examine several approaches to achieving generalization in AI, with a focus on the trend of scaling up large-scale neural networks. We'll explore the transformer architecture as an example of this approach.\n",
    "\n",
    "3. To provide hands-on experience with deep learning and PyTorch, using the Transformer-based Optical Character Recognition (TrOCR) model developed by Microsoft as an example of integrating visual and textual data.\n",
    "\n",
    "We'll look at handwriting recognition and text generation to illustrate the practical application of transformers in AI. We chose handwriting as a task that could be viewed through the lens of AI, neuroscience and cognitive science. That means we'll get to see how different people, with different interests, can look at a similar problem, and yet view generalization through different perspectives.\n",
    "\n",
    "Throughout the session, we'll cover the transformer architecture, its components, and how it has been adapted for various tasks, including for natural language processing and vision. We'll review key components of the transformer archtiecture, including tokenization, the attention mechanism, and classification heads. We'll discuss the training of these models, including scaling laws that describe how model performance relates to data size and computational resources. That will help you understand the current trends in AI in scaling to ever larger model sizes and datasets. \n",
    "\n",
    "By the end of this session, you'll have a good understanding of generalization in AI and some practical experience applying these concepts. Let's dive in and explore the fascinating world of generalization across artificial intelligence, neuroscience, and cognitive science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c633817-98cd-4817-aa74-cce6792f5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "\n",
    "video_ids = [('Youtube', 'W5o_HTsef0I'), ('Bilibili', 'BV1ho4y1C7Eo')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6df3b-e096-40cc-ad84-f83de132bbfa",
   "metadata": {},
   "source": [
    "## Slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d94cf-5a3e-44ac-b6bc-0c350fe66533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown\n",
    "from IPython.display import IFrame\n",
    "link_id = \"rbx2a\"\n",
    "print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272dbc70-f36b-446b-acfa-5b7df84c1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Intro_Video\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D1_Intro",
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
